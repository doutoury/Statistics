
# Two Envelope Paradox	(두 봉투 역설)

Let	봉투1 : X 달러
	봉투2 : Y 달러
							... x 와 y 에 대해서는 아무런 정보가 없다. 
							... 즉, 확률변수random variable 이라는 말.
	한 봉투에는 다른 봉투의 두 배의 금액이 들어있다.
	한 봉투에 x 가 들어있다면, 그 봉투를 열기 전에는 x가 원지 모름.
	하지만 다른 봉투에 x/2 또는 2x 가 들어있다는 사실은 앎.

problem.
	한 봉투를 열어보고 바꿀 기회를 줄 때, 바꾸는게 이득? 안이득?


Intuitive paradox.

	여기서 두 수 x/2 와 2x 의 평균을 내면 5x / 4 로 x 보다 큰 수가 됨
	y 봉투가 평균적으로 더 나은 기대결과를 갖네? 잉..? 그럼 무조건 바꿔야 겠네 ?

	근데, 다시 Y봉투에 대해 같은 argument를 적용하면 다시 X봉투가 평균적으로 더 나은 기대결과를 갖네..
	또 바꿔 ? 




-> 이에 대해 두 가지 상충하는 주장 competing argument 이 있다

Argument1.

	E(Y)	= E(X)					... by Symmetry

	첫 번째 주장은 E(Y) 와 E(X) 가 대칭성에 따라 같다는 생각

		만약, 우리가 알고 있는 정보가
		'봉투에 돈을 넣은 사람이 왼손잡이고, 왼손잡이는 무의식적으로 왼쪽에 돈을 더 많이 넣는다' 면
		그럼 문제는 비대칭asymmetry 가 된다 !

		하지만 지금 이 문제는 비대칭이 아니다. 대칭적인 상황.
		왜냐하면 왼쪽봉투보다 오른쪽봉투가 더 많다는 근거가 될만한 정보가 없기 때문.

							두 봉투가 비대칭적인 값을 갖을 것이다는 
							근거조건이 없기 때문에 비대칭으로 보기 
							어렵고, 그렇기 때문에 대칭적 상황이라는 
							것을 떼어놓고 이야기 하기 어렵다 !
	따라서 이 주장은 꽤 설득력 있다



argument2.

	E(Y)	= E(Y | Y=2X) P(Y=2x) + E(Y | Y=X/2) P(Y=X/2)
		= E(2X) P(Y=2X) + E(X/2) P(Y=X/2)	
						... Y=2X 라는 조건에서, Y=2X 니까 E(Y | Y=2X) 는 E(2X)
						(동어반복 같은데 ;; 맞는 말이긴 하네)
		= 1/2 E(2X) + 1/2 E(X/2)
						... by Symmetry
						Y=2X 일 확률과 Y=X/2 일 확률은 같다. 따라서 둘 다 1/2
		= 5/4 E(X)			
						... by LOTUS

	조건부에 관한 주장
	만약 확률을 모른다면, 우리가 아는 것에 대해 조건부를 사용해서 구할 수 있다.
						... 조건부라는 것을 제외하면 전체확률의법칙과 같다

	조건을 활용해서 기댓값을 분리하여 표현	... proof by 전체확률의법칙



Solution.
	그럼, 무엇이 참이냐 ?
	How to resolve this ? 

		두 경우가 모두 참인 경우가 존재하니 ?
		뭐, 두 봉투에 0 달러가 들어있거나, 무한대가 들어있는 경우일 텐데...
		양수의 돈이 들어있다고 보고, 현실적으로 무한대가 아니라고 볼 때는

		두 주장은 서로 모순contradiction 을 이루게 되고, 둘 중 하나는 반드시 틀리다.


	사실 대칭성Symmetry 에 반하는 주장이 맞다고 보기는 어렵다.
	대칭성Symmetry 이 우위에 있다. (take precedence)
	argument1. is prior argument.


Error.
	So, what's wrong with argument2. ?
	Actually This is one of the most common and troublesome mistake with conditioning,
	It's kind of like 'Use the information, and then forget of it.'

	조건부에 관한 흔하고 고질적인 실수 중 하나
	'어떤 정보를 사용한 뒤 잊어버리는 것'

--------------------------?????????????????????????????????????----------------------------

argument2.
	E(Y)	= E(Y | Y=2X) P(Y=2x) + E(Y | Y=X/2) P(Y=X/2)

			Y=2X 를 집어 넣을 때, condition Y=2X 를 잊으면 안됨
			이 단계에서 문제wrong 가 있었던 것

		= E(2X | Y=2X) P(Y=2X) + E(X/2 | Y=X/2) P(Y=X/2)

			... Y자리에 2X를 집어넣을 수는 있지만, 조건 | Y=2X 와 | Y=X/2 를 없애선 안됨!
			(이 조건부의 정보를 잊어버릴만한 근거가 없기 때문에)
			... 따라서 위에서 E(2X) P(Y=2X) + E(X/2) P(Y=X/2) 는 wrong!

			* E(Y | Y=2X)	not = E(2X)

		그럼 우리는 여전히 이 조건부 기댓값을 구해야 한다.
		E(2X | Y=2X) 와 E(X/2 | Y=X/2)



Approach.
	So, what's going on there ?	Let's think of this in terms of 'Indicator r.v.'
	지시확률변수에 관해서 생각해보자


Let	I be indicator of Y=2X
		: indicator of '어떤 봉투에 더 많은 돈이 들었는가'	... by Define 지시확률변수
		(Y=2X 면, 	I = 1, otherwise I = 0)		... 이 경우 Y가 X보다 돈이 두배 듦

Then,	X and I are dependent	
	(or Y and I are dependent)

		What that means ?
		It says that if you observe X then somehow that gives information about I. 
		만약 X를 관찰한다면, 어떤 식으로든 I 에 관한 정보informatio 를 준다는 의미.

			concrete thinking.
			왼쪽 봉투를 열어봤고 $100 를 보았다. 그럼 다른 봉투에는 $50 나 $200 있을 것.
			So the question is, "그게 I 의 확률을 바꾸니 ?"
			다른 봉투에 $50 또는 $200 들어있을 확률이 더 이상 50:50 이 아니게 되는 것 (???)
			이상하게 들릴 수 있지만, 이 상황에서 추가적인 정보가 없기 때문에 그렇다. (???)

		Essentially we just prooved that they have to be dependent, if the expected values are finite.
		기댓값이 유한일 때, 종속일 수 밖에 없다는 사실을 보였다.

			e.x.
			만약 왼쪽 봉투를 열었는데, $1 trillion (1조 달러)가 들어있었다.
			행복하겠지만, 우리가 느끼기에 1조 달러가 크다고 느껴진다고 해서
			다른 봉투에 돈이 절반만 들었을 것이다 생각할 수 있는 근거가 있니?
			0 ~ inf 무한한 수의 영역에서 봤을 때 1조는 그리 큰 수치도 아니다.
			

--------------------------?????????????????????????????????????----------------------------
			이 부분 뭔 소리 하는거야?

12:16 ~ 12:40
(조건부에 있는?) 정보를 집어넣을 때에는 정보를 없앨 수 없다는 사실을 항상 주의해야 한다
우리가 조건을 없앨 수 있는 유일한 순간은 서로 독립인 것을 알 때 뿐. (독립에 관한 근거필)

	하지만 이 Two Envelope Paradox 문제에서는 독립에 대한 근거justification 가 없으니
	X와 I가 서로 독립이다 (또는 Y와 I가 서로 독립이다) 라고 주장할 수 없다!

	사실 서로 독립이 아니다 (종속이다) 라고 하는 것 또한 자명obvious하지는 않지만,
	증명 없이 독립이다 라고 주장할 수는 없다. 근데 만약 증명하면 독립이 아니다라는 것 보이게 될 걸?






조건부 기대에 관한 또다른 예시

# Coin flipping problem	(동전 뒤집기 문제)

I call this 'Patterns in coin flips'

	repeated fair coin flips,	(... 전에 편향된 동전의 문제도 풀었다)
	we're going to wait and observe how pany flips until HT pattern
	계속 코인을 던지면서 얼마나 많이 던지기를 반복했는지 센다
	앞뒤의 패턴이 나올 때까지 기다리면서

	계속해서 동전을 던지다, 어느 순간 앞면이 나온 직후 뒷면이 나오는 순간이 있을 건데
	이 '특정 패턴이 나오는 순간', H 와 T 를 포함해 얼마나 많이 던졌는지를 세는 것이 문제

		... 비슷하게 HH 패턴이 나오기 까지 몇 번을 던졌는지도 문제접근이 가능 하겠지?
		(앞면이 두번 연속으로 나오기까지 던진 횟수	... or 대기시간)


Let's find the average

	How many fips until 'H-T' pattern ?	... let's call W_HT
	How many fips until 'H-H' pattern ?	... let's call W_HH

	해당 패턴이 나오기 까지 동전을 던진 횟수를 의미하는 W_HT 와 W_HH 모두 '확률변수' 이다.
	E(W_00) 은 해당 패턴이 나오기까지 기다린 시간(횟수)의 기댓값 이다.


Find 	E(W_HT)	and E(W_HH)


	이 문제를 풀기 앞서, 질적으로 등식이나 부등식이 있는지 살펴보자
	let's try think more qualitatively about whether there is an inequality or equality.


	We know there is three possibilities.

	01)	W_HT > W_HH
	02)	W_HT = W_HH
	03) 	W_HT < W_HH

	intuitively, 대부분 둘이 같다라고 생각 했다

	The answer is	E(W_HT)	= 4
			E(W_HH)	= 6	... 50% bigger !


		대칭성symmetry에 의해 같아야 하지 않나요?!	-> 대칭성의 잘못된 사용의 예. 
								(false use of symmetry)

		* Symmetry argument

		E(W_TT)	= E(W_HH)	by Symmetry	이 주장은 항상 성립한다
					왜냐하면 동전의 앞면 뒷면은 relabel 해도 달라지지 않기 때문 
					(labeling 에 따라 문제가 달라지지 않는다)
					So that's symmetry becuase I can interchange this T and H here.
		
		E(W_HT)	= E(W_TH)	by Symmetry	이 주작 역시 항상 성립한다

					But, 이 중 어느것도 위의 주장
		E(W_HT)	= E(W_HH)	인가? 에 대한 판별근거를 제시하지 못한다.
					대칭성symmetry 으로는 이에 대해 아무 논리도 펼 수 없다.
					becuase 아무리 H와 T를 바꿔도 HT 와 HH 는 서로 다른 패턴.

					... 대칭성Symmetry 에 대한 바른 이해
					* [언제 한번 대칭성의 통계적 의미와 수학적 의미 정리]
					패턴 or 수학적 특질이 동일한 두 대상


	Let's calculate that, then I'll talk more about intuition for why E(W_HT) is bigger E(W_HH).


first.	E(W_HT)

draw concrete situation.

	T	T	T	T	H	H	H	T
	|------------------ W_1 ----------------	|	|------- W_2 ------	|

	W_1	: Wait for the first time the coin lands head
	W_2	: Wait for the first time the coin lands tail	(additional after W_1)

	우리는 이 사건 W_HT 를 W_1 과 W_2 로 분리할 수 있다.
	첫 앞면이 나오기까지의 시간(횟수)와 첫 앞면이 나온 뒤 뒷면이 나오기 까지의 시간(획수) 로.

		* W_1 과 W_2 는 서로 독립이다.
		because the coin is memoryless (무기억성?)
		왜냐하면 동전은 결과를 기억할 수 없기 때문.

	E(W_HT)	= E(W_1) + E(W_2)		... by Linearity

					W_1 과 W_2 가 서로 독립이 아니더라도 선형성은 적용할 수 있다!
					평균을 구하는 데에 있어 두 사건의 평균으로 나누어 구할 수 있다!

		= 2 + 2			... since " W 는 Geometric dist. (기하확률변수) 를 따른다 "
		
		= 4				... 주의해야 할 점
						기하확률변수를 성공에 대해서 정의한다는 점. 따라서,
						W_j - 1 ~ Geom(1/2)

						... 성공하기까지의 대기시간과 같다
						... W_1 에서는 H가 나오는 것을 성공으로 봤고,
						... W_2 에서는 T가 나오는 것을 성공으로 보았다.
						Geom(1/2) 의 기댓값E 은 1 이므로, W_j 의 기댓값은 1+1

		평균적으로 W_1 이 일어나기 까지 2번 던져야 하고,
		평균적으로 W_2 가 일어나기 까지 2번 던져야 함을 의미



	같은 접근을 W_HH 에 대해서도 적용해보자

second.	E(W_HH)

draw concrete situation.

	T	T	T	T	H	T	T	...
	|------------------ W_1 ----------------	|	|------ W_1 반복 	... ?


					* The key distinction between W_1 pattern and W_2 pattern

					W_1	A partial progress.		(점진적 사건)
						W_1까지의 사건을 마무리 짓은 후W_2 사건으로 넘어감
						(W_1 이 마무리되면 W_HT 패턴의 절반이 완성됨)

					W_2	No partial progress.	(비점진적 사건)
						W_1까지의 사건을 마무리 지으면 W_HH사건이 끝나거나
						W_1까지의 사건이 마무리 되지 않고 W_1사건이 반복 됨
						(W_1 사건이


	Conditional expectation (조건부 기대) 를 이용하여 접근
	첫 번째 동전에 대해 조건부로 계산 		... (도박사들의 문제와 비슷?)


	E(W_HH)	= E(W_HH | 첫 번째 동전이 앞면인 경우) * 1/2 (첫 번째 동전이 앞면일 확률)
		+ E(W_HH | 첫 번째 동전이 뒷면인 경우) * 1/2 (첫 번째 동전이 뒷면일 확률)

			Just conditionaing on the two cases. 
			첫 시행의 결과가 H 인 경우와 T 인 경우



		E(W_HH | 첫 번째 동전이 뒷면인 경우)
		= (1 + E(W_HH))
					... " 첫 번째 동전이 뒷면 "	: 이미 한번 던졌음을 의미	
								= 1
					... 그 후에 다시 같은 problem으로 돌아옴
								= E(W_HH)

We're going to solve it in terms of itself
자기 자신에 대한 문제를 푸는 것

		E(W_HH | 첫 번째 동전이 앞면인 경우)
		= [2 * 1/2] + [(2 + E(W_HH)) * 1/2]

					... " 첫 번째 동전이 앞면 "	: 이를 다시 두 경우로 나누어 표현
								두 번째 동전의 case에 따라서

					우리가 이 조건부 기댓값 conditional expectation 을 구할 때
					첫 번째 동전이 앞 면이라는 걸 아는 상황에서 구하는 것
					That's the information we have.


					... " 두 번째 동전의 경우 "	: H 인 경우와 T 인경우

					case1. 
					첫 번째 동전이 앞면, 두 번째 동전이 앞면인 경우
					H H 로 사건 종료. 두 번 던진게 다니까 이 사건의 평균은
					= 2 * 1/2

					case2.
					첫 번째 동전이 앞면, 두 번째 동전이 뒷면인 경우
					H T 로 사건 되반복. 두 번 던진 것은 누적되고 다시 동일한 문제
					= (2 + E(W_HH)) * 1/2


	E(W_HH)	= E(W_HH | 첫 번째 동전이 앞면인 경우) * 1/2 (첫 번째 동전이 앞면일 확률)
		+ E(W_HH | 첫 번째 동전이 뒷면인 경우) * 1/2 (첫 번째 동전이 뒷면일 확률)

	E(W_HH)	= {2 * 1/2 + (2 + E(W_HH)) * 1/2} * 1/2 
		+ (1 + E(W_HH)) * 1/2


이제 E(W_HH) 자기 자신에 대한 방정식이 만들어 졌다. 이 방정식을 풀면,

	E(W_HH)	= 6



# Coin flipping problem	(동전 뒤집기 문제)

## Intuitive Interpretation

concrete situation.

	T	T	H	H	H	T	...	H	H	T	...
		|--- S ---	|

Question.
	이 동전이 공정함에도 불구하고 
	두 번을 던졌을 때, " 네 경우가 일어날 확률이 같다 " 는 사실이 왜 모순이냐 ?


Answer.
	Error perspective.

		T H 두 번의 사건만이 존재하는 구간 S 에 주목해 보자
		이 구간 안에서는 H H 와 H T 가 나올 확률이 동일하다 !
		Those are 1/4, same.
			... 이러한 관점으로 직관적으로 봐서 오류가 생김

		어떤 두 위치를 구간을 잡아도 그 두개의 구간 안에서는 일어날 확률이 같다.

		But, we are not just looking at two position. We're looking at the entire sequence.
		하지만 우리는 두 군데가 아니라, 전체의 순서를 봐야한다.

	Right perspective.

		전체 Sequence 에서 봤을 때, T H 의 등장은 T 와 H 가 바뀌는 지점에서만 관찰 되는데,
		전체 Sequence 에서 봤을 때, H H 의 등장은 H_1 다음 H_2 다음 H_3 ... 가 연속 등장할 때,
					(H_1 H_2) 와 (H_2 H_3) 가 중첩되어 관찰되게 된다 !

		H T 는 일반적으로 생각하는 만큼 등장하지만,
		H H 는 일반적으로 생각하는 것보다 더 자주 일어난다

			* 근데 동전 앞면과 뒷면의 총 횟수의 기댓값은 같기 때문에 
			연속적으로 등장하는 H H 는 간간히 떨어져서 나타날 거야. 
			그제 지금 일어나고 있는 일이다!

Application.
	이 문제를 동전 뒤집기 문제로만 생각할 수도 있겠지만,
	actually, 이는 유전학에서 중요하게 활용된다.

		유전학에서는 앞면, 뒷면 의 서열을 보는게 아니고 DNA sequence 를 본다
		A, C, T, G 의 알파벳으로 된 서열.
		유전학에서는 모티프라는 특정 패천을 연구하곤 한다.
		특정 패터이 DNA에서 나타나는가를 연구할 때 비슷한 문제를 맞게 된다

					* recommendation 
					TED	: 유전학 연구하는 통계학자 Peter Donnelly
						법정에서 일어나는 확률이야기를 해주는데
						이 문제와 비슷한 이야기를 다루고 있다

That's the waiting for certain sequences 
	특정 서열에 대한 대기시간을 알아보았다
	다양한 방향으로 확장할 수 있는데, 이건 굉장히 간단한 수준의 작업이었고 더 복잡한 문제를 만날 수 있다
	더 복잡하고 긴 서열을 다루는 문제들. 그런 문제들에 대한 방법론들이 있기는 한데,
	가장 기본적인 방법은 '조건부' 를 사용하는 것 !

	도박꾼의 파산 문제 (Gamblers ruin) 처럼 조건부 기대를 사용하였고, 
	복잡한 문제를 간단히 만든simplify 뒤에 첫 두개에 조건부를 사용해서 더 간단한 문제들로 쪼개는 것

That's a bsic idea of Conditional expectation. 






## General properties of conditional expectation

Conditioning on R.V.			... Coditioning on an event
확률변수에 조건부를 사용하는 법을 보자	지금까지는 사건에 조건부를 사용하는 것을 봤다

What does mean to conditioning on R.V ?
확률변수에 대한 조건부 사용과 사건에 대한 조건부 사용은 
아주 밀접하게 연관되어 있다. 하지만 둘 혼동하기 쉬우니 주의

	E(Y | X=x)

	Make sure completely clearly on what this means, both intuitively and mathematically.
	이 식의 의미를 정확하게 알아야 한다. 직관적인 면에서와 수학적인 면에서 모두.

	What does this expression actually means? 

		여러번 말하지만
		'X=x' is an EVENT. 
		In assuming that capital X and Y are RANDOM VARIABLES. little x is a number. 
		
		And we're conditioning on that even, X=x. 

		조건부라는 걸 제외하면, 그저 기댓값의 정의를 사용하면 됨.


in discrete case.
	E(Y | X=x)	= Sig_y y * P(Y=y | X=x)	
					... value * PMF
					... by def. of Expectation
					... X=x 정보(조건)가 주어진 상황에서
					... Y=y 의 기댓값을 구한다는 의미

		That's all this expression means.
		우리는 X=x 로 주어졌다는 걸 알고 있으니
		그 정보에 대해 조건부를 사용하는 것

		It's the best prediction of the value of Y given the information, X=x.


In continuous case.
	E(Y | X=x)	= Integral_inf y f_Y|X (y | x) dy
					... value * PDF
					... by def. of Expectation

if X is also continuous,
	E(Y | X=x)	= Integral_inf y {f_X,Y (x, y) / f_X (x)} dy
					... 이 경우 conditional PDF 를 어떻게 구했는지 기억해봐
					... Conditional PDF 의 정의는 Conditional probability 와 매우 유사
					... 확률 대신 밀도가 들어있는 것 뿐
					... Y 교사건 X 의 밀도density 를 X의 밀도density 로 나눈 것
					... Joint PDF of X, Y / Marginal PDF of X
					... by def. of Joint PDF
					[ Joint PDF = Conditional PDF * Marginal PDF ]

	조건부 확률밀도함수를 두가지 방법으로 표현해 봄 (just by analogue)



이렇게 합과 적분을 이용해 조건부 기댓값을 계산해 보았다.
이것만으로는 어떤 특성을 갖는지 알 수 없다


### Conditioning Expectation given an EVENT
사건이 주어졌을 때의 조건부 기대

Let	g(x)	= E(Y | X=x)
					* E(Y | X=x) 이런 계산을 할 때 자주하는 실수
					통계적 표기notation 에 대한 문제. 
						capital X and samll x
						X 는 확률변수 random variable 로 함수고
						x 는 그냥 변수. 숫자. 

	g(x)	는 x 에 대한 함수고,
	E(Y | X=x)	도 x 에 대한 함수다.

		X=x 라는 정보가 주어졌을 때 'x 에 대한 함수' 
					... (확률변수 X, Y 를 포함하지 않는다!)
		X와 Y가 서로 독립이라면, E(Y)가 되는데 이는 '상수 함수'
					... (X에 관한 조건이 Y에 관해 아무런 정보를 주지 않으므로)


### Conditioning Expectation given an R.V.
확률변수가 주어졌을 때의 조건부 기대

define	g(X)	= E(Y | X)	
					* E(Y | X)
					여기서는 capital X
					역시 표기를 제대로 이해하여야 한다

	What this thing mean?

	We have the function g of little x. and we replace little x by big X. After evaluating ! Not before !
	이미 계산한 x 에 대한 함수 g(x) 의 변수 x 에 확률변수 X 를 넣은 것.
	
		g(x)	= E(Y | X=x) 	함수에 x = X 를 대입해서
		g(X)	= E(Y | X=X) 	가 되어
			= E(Y)		가 될거라 생각하는 오류!

					이러면 X = X 라는 새로운 조건부에 대해 Y의 평균을 구하므로
					g(X)	= E(Y)	네? 하는 오류에 봉착한다.

	That's not what that means.

	g(x) 를 이미 계산한 함수로 봐야한다.
		e.g.	if g(x) = x^2	, then g(X) = X^2

		x에 관함 어떤 함수에 대하여 그 함수를 구한 뒤에 X로 바꾸어 넣는 것.
		그 결과는 확률변수 r.v. 라는것 주목 !
		g(X)	= E(Y | X)		는 확률변수다
					X의 함수로 주어진 확률변수	... 변수변환 (?)
					It's a funtion of X. It's a R.V.

	That's what that means.


Intuitive Interpretation.
	E(Y | X) means	우리가 X를 관찰하고 X의 값을 알고 있을 때, X를 known constant 로 취급하는 것
			That's what this says.

			Assuming we get the pretend that the X is known, 
			And finding what's are best prediction of Y. 
			그러면 X의 함수가 됨.

	That's what that means intuitively.



Let's do couple of examples

### Example of Conditional Expectation	: with Poisson dist.

Let	X and Y are i.i.d. ~ Pois(lmd)
	X 와 Y 가 독립항등분포이고, 포아송 분포 Pois(lmd)를 따른다

Find	E(X+Y | X)	= E(X | X) + E(Y | X)
					... by Linearity
					선형성은 조건부 기댓값에서도 유효하다!
					because. 조건부 확률도 확률이기 때문

	확률변수 X를 (X의 분포를?) 알고있다는 가정 하의 조건부 기대

						확률에서의 모든 성질은 조건부 확률에서도 쓸 수 있다
						조건부 기대(평균)도 조건부 확률로 정의되기 때문에
						조건부 기대(평균)도 기댓값의 성질을 따른다
						따라서 기댓값의 성질인 선형성 같은 성질을 만족

			What does these things mean?
				E(X | X)	= X	... X를 알면서 X를 예측하면 X임
						X를 그대로 예측값prediction으로 사용하므로
				E(Y | X)	= E(Y)
						... by X and Y are i.i.d.
						... by independence
						서로 독립이므로 X를 알아도 Y를 예측할 때 무용지물

					* E(h(X) | X)	= h(X)
					h 가 임의의 함수일 때, X를 알게되면, h(X)를 알 수 있다
					We can just compute it. No uncertainty about it. ... (?)
					(나중에 배울 성질이지만 지금 잠깐 언급)

			= X + E(Y)
			= X + lmd		... by Poisson dist. 의 기댓값

이 예시를 통해
	01. 조건부 기대에서 선형성linearity을 여전히 쓸 수 있다
	02. 조건부에서 서로 독립이라면 무시할 수 (버릴 수) 있다
	03. 조건부 기대 안에 완전히 아는 것이 있다면 그대로 빼낼 수 있다
	는 사실을 배웠다


### Example of Conditional Expectation	: with Poisson dist.

위와 반대로된 문제 (reverse case)

Let	~ same ~

Find	E(X | X+Y)

	01. 이 문제에서는 선형성을 쓸 수 없다.
	[E(X | X+Y) is not	= E(X | X) + E(X | Y)]

	What does mean? 


way1. 	Straight to definition of Expectation

	let's find PMF first.
	Let	T = X + Y, 	and find 	conditional PMF.

		P(X=k | T=n)	= P(T=n | X=k) * P(X=k) / P(T=n)

						... by Bayes rule

						... k and n are dummy variable 
						(별로 중요하지 않습니다)
						... 그저 T를 알고 있을 때, 
						X의 조건부 분포를 알고싶은 것

				= P(Y=n-k | X=k) * P(X=k) / P(T=n)

						... T = X + Y 이므로 Y = T - X 이고 y = k - n
						라고 해석해도 되는건가, 확률변수에 대해	(???)
						아님, T=n 인 사건은 X+Y=n 인 사건을 의미하므로, 
						X=k 임을 관찰하여 알 때는 k+Y=n 인 사건을 의미하나?!	
						... X = k 일때, T = n 인 사건은 Y = n - k 인 사건과 같다
											(???)
				= P(Y=n-k) * P(X=k) / P(T=n)

						... X and Y are independent
						So Y=n-k 에 대해 X=k 조건부 없앨 수 있다

				= {e^(-lmd) lmd^(n-k) / (n-k)!} * {e^(-lmd) lmd^(k) / (k)!}
				/ {e^(-2lmd) (2lmd)^(n) / (n)!}
						
						... by PMF of Poisson dist. 
						X 와 Y 는 포아송분포를 따르므로

						... denominator (분모)
						... by properties of Poisson dist.
						독립적인 포아송분포의 합은 포아송분포를 따름
						X~Pois(lmd), Y~Pois(lmd) 일 때,
						X+Y ~ Pois(2lmd) 를 따름 (???)

				이 식을 simplify 해보면, 굉장히 familiar distribution 을 얻게 된다
				What distribution is this?	Binomial dist.

				= n! / (n-k)! * 1 / 2^n
				= nCk * 1 / 2^n	
						... 이항분포식 ! Binomial dist.

		베이즈 법칙 Bayes rule 을 통해 X | T=n ~ Bin(n, 1/2) 를 알았다

	이를 이용해 조건부 기댓값 conditional expectation 구해보자

	Find.	E(X | X+Y)

		어떤 사건에 대한 조건부 경우를 먼저 살펴보자
		E(X | T=n)	= n / 2		
						... by expectation of Binomial dist.
		
		특정 사건에 대한 조건부 대신, (확률변수) T 에 대해서 조건부를 써보면
		E(X | T) 		= T / 2
						... replace 'n' by 'T'
						... according to definition (of what?)
		
		즉. 만약 T 를 알고 있다면, 가장 좋은 예측prediction 은 T / 2 라는 말!

						... That's actually pretty intuitive result.
						X 와 Y 가 독립이며 같은 분포를 따르는데 (i.i.d. 한데), 
						만약 X 와 Y 의 합을 알고 있을 때,
						그 중 하나의 평균을 예측하고 싶다면, 
						X 와 Y 의 총합이 100 이라면 각각 50이라고 추정
						이러한 직관적 추정을 위에서 수학적으로 증명한 것


way2. 	Notice the symmetry (대칭성에 주목)

		E(X | X+Y)	= E(Y | X+Y)	... by Symmetry
						... since i.i.d.  (서로 독립이고 같은 분포를 따르기 때문)

		i.i.d. 면 이는 항상 성립한다. 포아송 분포가 아니더라도. 

		E(X | X+Y) + E(X | X+Y) 	= E(X+Y | X+Y)
						... by Linearity
					= X+Y
						... by ' E(h(X) | X) = h(X) '

		2 E(X | X+Y)		= T
		E(X | X+Y)		= T / 2
						... 증명 끝.

	여기서는 포아송분포에 관한 성질을 쓰지 않았다.
	Actually more general resolution.







# Iterated Expectation				(= Adam's Law)
	반복기대					(= 전체 기댓값의 법칙)

This is the simgle most important properties of conditional expectation

	E(Y | X)	가 확률변수r.v. 라고 위에서 얘기 했지?
	그럼 '그' 확률변수의 기댓값은 무엇일지 궁금해진다

	E(E(Y | X))		= E(Y)			This is clesely related to 'the Law of total probability)
						이는 '전체확률의법칙' 과 깊은 관련이 있다.
						-> " 전체확률의법칙을 아주 압축해 적은 것 "
	(아주 유용한 정리이다)

