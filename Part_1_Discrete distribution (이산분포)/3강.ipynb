{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3강.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyPVuoXwu6SSMtEpJGzRx1PE"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Foyuuc34YokM","colab_type":"text"},"source":["# 3강 <br>\n","\n","  - ### __Birthday Problem__ <br>\n","  - ### __Properties of Probability__\n","\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"4rDed7RlYwUd","colab_type":"text"},"source":["We do one of the most famous problems in probability to start with, and then we'll go back into __'the Non-naive definition'__. <br>\n","The problem is that everyone who studies probability should be familiar with, that's called __'the Birthday Problem'__. <br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"m_pLSptOZpCQ","colab_type":"text"},"source":["## Birthday Problem <br><br><br>\n","\n","\n","_\" How likely is it that you can find at least one pair of people who share the same birthday? \"_ <br><br>\n","\n","_ \" How many people do you need in order to have at least a 50:50 chance that two people will have the same birthday? \"_ <br><br>\n","\n","These kinds of ask are called the Birthday Problem. <br>\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"3WAba3YdfZUD","colab_type":"text"},"source":["### Assumption <br><br>\n","\n","[ ~ 04:30 Assumption for Birthday Problem ] <br><br>\n","\n","~\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"zHhwS0JGfmkV","colab_type":"text"},"source":["### Pattern & Structure <br><br>\n","\n","\n","~\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"RAaIJFj1h00N","colab_type":"text"},"source":["### Approximation computation <br><br>\n","\n","[ 11:00 ~ 17:30 ] <br><br>\n","\n","Probability of a match : This is the result of the _'Birthday Problem'_ <br><br>\n","\n","$P(match) \\approx \n","\\begin{cases} \n","50.7 \\% \\qquad , \\; if \\;\\;\\; k=23 \\\\ \n","97.0 \\% \\qquad , \\; if \\;\\;\\; k=50 \\\\\n","99.9 \\% \\qquad , \\; if \\;\\;\\; k=100 \n","\\end{cases}$ <br><br>\n","\n","This is unobjectionable. This is correct, but it's not that intuitive. <br>\n","How could it get 100 people 99.99 % likely, among 365 people? <br><br>\n","\n","#### Intuition <br><br>\n","\n","Here, this _'Birthday Problem'_, $k$ is not the relevant thing. $\\binom {k}{2}$ is the relevant thing ! <br>\n","There are $k$ people, but there are $k$ choose $2$ pairs of people. So that's the more relevant thing to do be looking at here.mind\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"pPF-8ixIajLw","colab_type":"text"},"source":["### Non-Naive definition of probability <br><br>\n","\n","Let's come back to _'the Non-Naive definition of probabiliry'_. <br><br><br>\n","\n","\n","\n","__Non-Naive definition of probability__ <br>\n","These are the 2 conditions that $P$ has to satisfy. <br><br>\n","\n","#### __Axioms__ <br>\n","\n","  1. $P(\\varnothing) = 0 \\qquad , \\; P(S) =1$\n","  2. $P(\\bigcup_{n=1}^{\\infty} A_n) = \\sum_\\limits{n=1}^{\\infty} P(A_n) $ &emsp; &emsp; &emsp; , if $A_1, A_2, ... , A_n$ are __disjoint__ (non-overlapping)\n","<br><br><br>\n","\n","\n","\n","#### __Intuition__ of _'the Non-Naive definition of probability'_ <br>\n","\n","  - 1st intuition of probability <br>\n","  We can think of probability as __area__. \n","  >S[ A_1( ) , A_2( ) , A_3( ) ] <br><br>\n","  >\n","  >Suppose that the area of the S region is 1. <br>\n","  >Then all it says is that the union is this A_1( ), A_2( ), and A_3( ), The area is A_1 area + A_2 area + A_3 area in terms of Venn diagram. <br>\n","  >And we could extending the upper limit of number of sets from finite number to infinitely many of them.\n","\n","  - 2nd intuition of probability <br>\n","  Later we'll think of it more sophisticated. \n","\n","<br><br><br>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KM73Tkwmr21F","colab_type":"text"},"source":["#### __Big breakthrough in probability__ <br><br>\n","\n","These 2 conditions that $P$ has to satisfy for the Non-Naive definition of probability was a __big breackthrough__. <br><br>\n","  1. __One big breakthrough__ in probability <br>\n","  I mentioned before that was __\" to think of it in terms of sets and events and unions and intersections, and things like that. \"__ <br><br>\n","  2. __The other big breakthrough__ <br> \n","  mathematically speaking was just writing down __\" these 2 axioms. \"__ <br><br><br>\n","\n","\n",">__Argument of what's the probability__ <br>\n",">Before we just had these 2 axioms of the Non-Naive def. of prob., it was haarder to say what's a correct argument in probability, and what's an incorrect argument. <br><br>\n",">\n",">\n",">__Meaning of probability__ <br>\n",">There were a lot of philosophical debates about, what is the meaning of probability? And those debates continue to this today. <br><br>\n",">\n",">And I think, in statistics, it's important to think about these foundational issues, what does probability really mean? In the real world. It's important but that's not the main subject for this course. <br><br>\n",">\n",">__Mathematical point of view__ <br>\n",">And it didn't lead to as much progress as just having these rules. Because basically, from a mathematical point of view, as long as you have a $sample \\; space$, and you have a function $P$ satisfying these 2 axioms, which you know $P$ is a function that takes events as input and returns a number between 0 and 1, satisfying those 2 axioms. <br><br>\n",">\n",">As long as that's true, then we consider $P$ a probability, and every theorem about probability that we do then is applicable, and we don't have to worry what does it really mean. <br><br>\n",">\n",">__Two Axioms of Non-naive def. of prob. (Big breakthrough)__ <br>\n",">There are different interpretations of probability that people can debate and people can use. But as long as interpretation satisfies these 2 axioms, then we'll be okay. <br><br>\n","\n"]},{"cell_type":"code","metadata":{"id":"3iXSCVqcmIeJ","colab_type":"code","colab":{}},"source":["# library\n","import matplotlib.pyplot as plt\n","from matplotlib_venn import venn2\n"," \n","# First way to call the 2 group Venn diagram:\n","fig = plt.figure()\n","fig.patch.set_facecolor('black')\n","\n","venn2(subsets = (10, 5, 2), set_labels = ('Group A', 'Group B'))\n","plt.show()\n","\n","# Second way\n","venn2([set(['A', 'B', 'C', 'D']), set(['D', 'E', 'F'])])\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N5Q8kMONkAl3","colab_type":"text"},"source":["## Properties <br>\n","\n","Just from (using) 2 axioms of probability, we can derive every theorem that's ever been derived about probability. <br><br>\n","\n","[ 22:00 ~ ] <br><br>\n","\n","  1. $P(A^c) = 1 - P(A)$ <br><br>\n","\n","  >__Intuitively__ <br>\n","  >In the picture of Venn diagram, it should be intuitively clear (obvious). $A$ is inside of $A( )$ and $A^c$ is outside of $A( )$. <br><br>\n","  >S[ A_1( ) , A_2( ) , A_3( ) ] <br><br>\n","  >\n","  >__Proof__ <br>\n","  >The proof is just the media for use Axiom(1) and Aximon(2) <br><br>\n","  >\n","  >$1 = P(S) = P(A \\cup A^c)$ &emsp; &emsp; &emsp; ... by Axiom(1) <br>\n","  >$P(A \\cup A^c) = P(A) + P(A^c)$ &emsp; ... by Axiom(2) <br>\n","  >&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; ... since $A \\cap A^c = \\varnothing$ &emsp; ($A$ and $A^c$ are disjoint)\n","\n","<br><br>\n","\n","  2. $if \\quad A \\subseteq B , \\qquad then \\quad P(A) \\leq P(B)$ <br><br>\n","\n","  >__Intuitively__ <br>\n","  >In terms of Venn diagram, This is obvious too. B( ) is like a bigger area containing the smaller one. B( ) could be thought as being split into two parts. There's A( ), and the rest area in B( ). <br><br>\n","  >S[ B( &ensp; A( ) &ensp; ) ] <br><br>\n","  >\n","  >__Proof__ <br>\n","  >Decompose B( ) into two parts, the area of A( ) and the other area of B( ) that's not in A( ). and these are disjoint.<br><br>\n","  >\n","  >$B = A \\cup (B \\cap A^c)$ &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &ensp; ... $A$ and $(B \\cap A^c)$ are __disjoint__ <br>\n","  >$P(B) = P(A) + P(B \\cap A^c)$ &emsp; &emsp; &emsp; ... by Axiom(2) <br>\n","  >$P(A) + P(B \\cap A^c) \\geq P(A)$ &emsp; &emsp; &emsp; ... by def. of prob. &nbsp; ($0 \\leq p \\le 1)$\n","\n","  (It's assumed that probability is always between 0 and 1, I didn't write $0 \\leq p \\le 1$ as an axiom)\n","\n","<br><br>\n","\n","  3. $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$ <br><br>\n","\n","  >>*&nbsp;__Non-disjoint__ set problem <br>\n","  >>How do we get __'the probability of a union'__? We often want the probability of a union and we're not necessarily so lucky as to have only disjoint sets. <br>\n","  >\n","  > <br>\n","  >\n","  >__Intuitvely__ <br>\n","  >on Venn-diagram, subtract intersection double counted. <br><br>\n","  >\n","  >S[ A( B{ ) } ] <br><br>\n","  >\n","  >__Proof__ <br>\n","  > When you're confronted with a problem like this, you don't know how to prove it, let's think of kind of a strategy that we have to somehow apply those __Axioms__. But this Axiom(2), which is the most important one, only applies when sets are disjoint. So somehow we have to make things disjoint, right? So that's the strategy. <br>\n","  >\n","  >>__*&nbsp;disjointification__ <br>\n","  >>\n","  >>$P(A \\cup B)$ Right here I can't apply the Axiom(2) because $A$ and $B$ are not disjoint. So to make sets disjoint we're going to write $P(A \\cup B)$ in a different way, a disjoint way. I call this disjointification.\n","  >\n","  ><br>\n","  >\n","  >$P(A \\cup B) = P(A \\cup (B \\cap A^c))$ &emsp; &emsp; &emsp; ... $A$ and $(B \\cap A^c)$ are __disjoint__ ! <br>\n","  >&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &ensp; ... now, we can apply the Axiom(2) ! <br>\n","  >>Proof process of __Properties 2.__ <br>\n","  >>$P(A \\cup (B \\cap A^c))$ here we take $A$, and then take everything in $B$ excluding the stuff that we already had from $A$. Now, $set \\; A$ and $set \\; (B \\cap A^c)$ are __disjoint__. \n","  >\n","  ><br>\n","  >\n","  > $P(A \\cup (B \\cap A^c)) = P(A) + P(B \\cup A^c)$ <br><br>\n","  >\n","  >*&nbsp;__wishful thinking__ <br>\n","  > $P(A) + P(B \\cup A^c) \\stackrel{?}{=} P(A) + P(B) - P(A \\cap B)$ <br>\n","  >>I wish this is true. I want to see whether it's true. Now I'm going to try to compare this left term and right term. This will be true __if and only if__ this $P(B \\cap A^c)$ is the same as this $P(B) - P(A \\cap B)$. \n","  >\n","  >equivalent to. <br>\n","  >$P(A \\cap B) + P(B \\cap A^c) \\stackrel{?}{=} P(B)$ <br>\n","  >> Now we just have to check, is this true. <br>\n","  >> This is true immediately, by Axiom(2). Since $set \\; (A \\cap B)$ and $set \\; (A^c \\cap B)$ are __disjoint__  \n","\n","<br>\n","\n","&emsp; &emsp; This rule is a simple case of what's called __inclusion and exclusion__. \n","\n","<br><br><br>\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gPIifFur-u4V","colab_type":"text"},"source":["### Inclusion-Exclusion rule (general ver.) <br><br>\n","\n","\n","#### Probability of the union <br>\n","\n","  - Adjusting for double counting __by alternating summation of inclusion and exclusion__. <br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"v5ls2DI8nBDA","colab_type":"text"},"source":["#### Triple case of probability of the union <br><br>\n","\n","  - $P(A \\cup B \\cup C) = P(A) + P(B) + P(C) - P(A \\cap B) - P(A \\cap B) - P(A \\cap C) + P(A \\cap B \\cap C)$ <br><br>\n","  >__Intuitvely__ <br>\n","  >in the picture of Venn-diagram <br><br>\n","  >\n","  >$+P(A \\cap B \\cap C)$ <br><br>\n","  >\n","  >Adding the stuff in the triple intersection, we have not couted. <br>\n","  >That's __inclusion-exclusion rule__ in the triple case.\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"Rn_Y5rMSpaBK","colab_type":"text"},"source":["#### The general case ($N$) of probability of the union <br><br>\n","\n","  - $P(A_1 \\cup A_2 \\cup \\ \\cdots \\ \\cup A_n) = \\displaystyle\\sum_{i=1}^{n} P(A_i) - \\displaystyle\\sum_{i<j} P(A_i \\cap A_j) + \\displaystyle\\sum_{i<j<k} P(A_i \\cap A_j \\cap A_k) + \\ \\cdots \\ + (-1)^{n+1} \\ P(A_1 \\cap A_2 \\cap \\cdots \\cap A_n)$ <br><br>\n","  >__Intuitively__ <br>\n","  >in the picture of Venn-diagram, accounting for the union in a tedious way, counting intersection areas. <br><br>\n","  >\n","  >__Proof__ <br>\n","  >like proof of properties 3. of probability, using 'disjointification' and Axiom(2) we get proof, but it's so tedious. <br><br>\n","  >\n","  >__Induction__ (유도, 귀납법) <br>\n","  >There's more clever way to proove this. It's comletely 'analogous'. It's just a more tedious way, but as __general way__ you can use induction. <br>\n","  >>Summing up alternating including and excluding intersections. <br>\n","  >>we can intuitively understand the alternating including and excluding intersections.\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"9zZzPyQry_RU","colab_type":"text"},"source":["### Example : Inclusion-exclusion problem <br><br>\n","\n","__de Montmort's Problem (1713), matching problem__ <br><br>\n","\n","Don't care about the name of the problem, <br>\n","Do care about the concept of the problem! <br>\n","\n",">It's a pretty natural problem that comes up in different contexts. There are many different ways we could phrase this problem. Different forms of the same thing in different disguises.\n","\n",">It's a famous interesting example of inclusion-exclusion, how you can apply it to a problem.  \n","\n","<br>\n","\n",">Not surprisingly, this originated from considering a gambling game. de Montmort was interested in a lot of different gambling problems. In 1713, Probability was still in its infancy, and he was studying some of these gambling problems. Which had real practical consequences for gamblers, there's a lot of money at stake in this, that was the motivation. \n","\n","<br><br>\n","\n","### Problem <br><br>\n","\n","#### Story <br>\n","there's $n$ cards, labeled $1, 2, ... , n$. what's the probability that at least one card, when flipped over at the $n$th time(turn), has the $n$ number on the card? <br><br>\n","\n","\n","#### Mathematical expression <br>\n","\n","There are $n$ cards, labeled $1, 2, ... , n$. Let $A_j$ be the event \" $j$th card matches \". Solve $P(A_1 \\cup A_2 \\cup \\ \\cdots \\ \\cup A_n)$. <br><br><br>\n","\n","\n","\n","To define the probability, we need to __define events !__ <br>\n","> <br>\n","> Let $A_j$ be the event \" $j$th card matches \" <br>\n",">(in other words, the $j$th card in the deck is numbered as card $j$) <br>\n","> <br>\n","\n","<br>\n","\n","\n","#### * Note : the probability that __\"at least one card matches\"__. <br>\n","\n","> <br>\n",">$P(A_1 \\cup A_2 \\cup \\ \\cdots \\ \\cup A_n)$ <br><br>\n",">\n",">__The probability of the union__ is a mathematical expression for the probability for \"the probability that at least one card matches\". <br>\n","> <br>\n","\n","<br>\n","\n","Luckily, in this problem, we have a lot of __' symmetry '__. <br>\n","We should take advantage of symmetry whenever we can. <br><br><br>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rmx5DLqOw4L2","colab_type":"text"},"source":["#### Mathematical calculation <br>\n","\n","<br>\n","\n","  0. $P(\\bigcup \\limits_{i=1}^{n} A_i)$ <br><br>\n","\n","  $= P(A_1 \\cup A_2 \\cup \\ \\cdots \\ \\cup A_n) \n","  = \\displaystyle\\sum_{i=1}^{n} P(A_i) - \\displaystyle\\sum_{i<j} P(A_i \\cap A_j) + \\displaystyle\\sum_{i<j<k} P(A_i \\cap A_j \\cap A_k) + \\ \\cdots \\ + (-1)^{n+1} \\ P(A_1 \\cap A_2 \\cap \\cdots \\cap A_n)$ <br><br>\n","  \n","  First, We have to write out this sum using inclusion-exclusion rule to sum of probabilities with intersection. <br>\n","  $*$ Note : we describe subscripts of order number just for concreteness ! <br><br><br>\n","\n","  $1$. $P(A_j) = \\frac {1}{n}$ <br><br>\n","  \n","  Second, find $P(A_j)$, which is the probability that the $j$th card in the deck is card $j$. You can do this using a __Naive def. of prob.__ There's two ways to think of this. <br><br>\n","    - One way would be to have $N$ factorial as the denominator because we're using a Naive def., assuming all permutations of the deck are equally likely.\n","    - But, easier way to think of it is just that it's $1/N$ because all positions are equally likely for the card labled $j$. <br><br>\n","  \n","  > Imagine I'm looking for the ace of spades where 52 cards are. The ace of spades is equally likely to be abywhere so there's a one in 52 chance that is in any specific position. So, that's immediately $1/N$. you can also derive this using __Naive definition__ with an $n$ factotial, $\\frac {(n-1)!} {n!}$. You get the same thing. <br>\n","  \n","  >Notice this $P(A_j)$ does not depend on $j$. That's what saves us here. If we had like some complicated thing involving $j$ and $n$ here, then we're gonna have to do a summation. But there's no $j$ here, so that means we're just gonna multiply this by $n$. \n","\n","  <br><br>\n","\n","  $2$. $P(A_1 \\cap A_2) = \\frac {(n-2)!}{n!} = \\frac {1}{n(n-1)}$ <br>\n","  (It's the same event with $(A_i \\cap A_j)$ where $i$ not equal $j$) <br><br>\n","\n","  Using __symmetry__. by Naive definition. There are $n$ factorial possible permutations of the deck of cards. <br> \n","  And what is this $A_i \\cap A_j$ $event$ say is that the card on top of the deck has a $i$ on it, and the card that is second has a $j$ on it. The other $(n-2)$ cards can be in any order whatsoever, so for the rest of them is $(n-2)!$. \n","\n","  <br><br>\n","\n","  ... continuing in this way ...\n","\n","  <br><br>\n","\n","  $k$. $P(A_1 \\cap A_2 \\cap \\cdots \\cap A_k) = \\frac {(n-k)!}{n!}$ <br><br>\n","  \n","  What that says is that the first $k$ cards are exactly one up to $k$. The remaining (n-k) cards can be in any order whatsoever. <br>\n","  So the denominator is still $n!$, the numerator is $(n-k)!$. <br><br>\n","\n","  That looks kind of messy, but the nice thing is that we have __symmetry__, so this $A_1$, $A_2$, ... and $A_k$ will work whatever choices you put there. <br><br>\n","  \n","  $P(A_1)$ &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp; there's $_{n}C_{1}$ <br>\n","  $P(A_1 \\cap A_2)$ &emsp; &emsp; &emsp; there's $_{n}C_{2}$ <br>\n","  ... <br>\n","  $P(A_1 \\cap \\cdots \\cap A_k)$ &emsp; there's $_{n}C_{n-k}$\n","  \n","  <br><br>\n","\n","  So now let's quickly apply __inclusion-exclusion__. <br><br>\n","\n","  $P(A_1 \\cup A_2 \\cup \\ \\cdots \\ \\cup A_n)$ <br><br>\n","  $= n \\frac{1}{n} - \\frac {n(n-1)}{2!} \\frac {1}{n(n-1)} + \\frac {n(n-1)(n-2)}{3!} \\frac {1}{n(n-1)(n-2)} + ...$ <br><br>\n","  $= 1 - \\frac {1}{2!} + \\frac {1}{3!} - \\frac {1}{4!} + ... + (-1)^{n+1} \\frac {1}{n!}$ <br><br>\n","  $\\approx 1 - \\frac {1}{e}$\n","  \n","  <br><br>\n","\n","  That's looks messy, but that's the exact answer. This looks ugly, but familiar. This should remind you of the __Taylor series__ for $e$ of the $x$. So this is approximately $1- \\frac {1}{e}$. <br><br>\n","\n","  (We're going to see this $\\frac {1}{e}$ alot in this class) <br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"TGPYKNm3weHE","colab_type":"text"},"source":["### Meaning of Inclusion-exclusion rule <br><br>\n","\n","$P(\\bigcup \\limits_{i=1}^{n} A_i)$ <br><br>\n","\n","Direct calculation for probability of union is pretty hard. <br><br>\n","\n","Inclusion-exclusion is the easiest way to do this. It says that the Probability of the union is what to add up the individual probabilities then to subtract the probabilities of different intersections, and then to add triple intersections, ... keep going like that. (alternating calculation). By the symmetry of the problem. <br><br>\n","\n","So __symmetry__ and __inclusion-exclusion__ is the key to this problem. <br><br>\n","\n",">This problem illustrates many things <br>\n","  - it illustrates $\\frac {1}{e}$ <br>\n","  - it illustrates __inclustion-exlustion__ <br>\n","  - it illustrates __the symmetry__ <br>"]},{"cell_type":"markdown","metadata":{"id":"7z8hB8lEGJGJ","colab_type":"text"},"source":["### The probability of no match <br><br>\n","\n","$1 - P(match) = P(no \\; matches)$\n","\n","The probability that there are __no matches__. (in set theory notation) <br><br><br>\n","\n","$P(no \\; matches)$ <br> \n",">$= P(\\bigcap \\limits_{i=1}^{n} A_i^c)$ <br> \n",">$= 1 - P(match)$ <br>\n",">$= 1 - 1 + \\frac {1}{2!} - \\frac {1}{3!} + \\cdots $ <br>\n",">$\\approx \\frac {1}{e}$ &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; (about 0.37)\n","<br>\n","\n","If you take __the complement of a union__, it's __the intersection of the complements__. <br><br><br>\n","\n","\n","$*$ Note\n","\n","> Whenever you see something that looks like __factorials__ in the bottom (denominator), that should be making you think of various __Taylor series__. <br><br>\n",">\n",">And the 2 Taylor series that we need over and over again in this class are __the geometric series__ and __the Taylor series for $e^x$__.\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"Iy3XdTcVKwca","colab_type":"text"},"source":["### Miss-intuition about the probability of the match problem <br><br>\n","\n","People's intuition about the match problem <br><br>\n","\n",">Most people who haven't seen this would guess that the probability of no match either goes to $0$, or goes to $1$, depends on whether you're a pessimist or an optimist. <br><br>\n",">Because if $n$ is getting very large, you have a billion cards. Now each one of those cards is exremelt unlikely to be in its position, but you have so many chances. So who's winning that competition between the fact that it's so unlikely for each one but you have so many of them? Somehow those 2 competing forces reduce(converge) to $\\frac {1}{e}$ "]}]}