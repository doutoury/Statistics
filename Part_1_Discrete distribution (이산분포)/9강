{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"9강","provenance":[],"private_outputs":true,"collapsed_sections":["XsAWkD2xcQew","e4GbhuTXg-N2","z6hz8dF1kMaN","pYKs1L-Ctyag","lwtJVWhx4blO","-2NCL4ed-6rx","M637UL0pOb7v","EEmMtLJIWOQI","xXUB5Ynchev8","3jE31C8Vrub-"],"authorship_tag":"ABX9TyOj70Uk5hEvtQmEmV5O+SjP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tzVumfxO1oxv","colab_type":"text"},"source":["# 9강 <br>\n","\n","  - ### Cumulative Distribution Funtion $\\quad$ (CDF) <br><br>\n","\n","  - ### Independent Random Variables <br><br>\n","\n","  - ### Expectation <br><br>\n","\n","  - ### Indicator Random Variables <br><br>\n","\n","  - ### Linearity <br><br>\n","\n","  - ### Geometric Distribution\n","\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"l8CyRAyl4n7N","colab_type":"text"},"source":["## Independence <br><br>\n","\n","\n","We've seen about independence intuitively before. <br><br>\n","\n","Now here, <br>\n","Let's see mathmatically what does independence mean on Random Variables.\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XsAWkD2xcQew","colab_type":"text"},"source":["### Independence of Random Variables <br><br>\n","\n","\n","$X, Y$ are independent Random Vriable <br>\n","If $\\quad P(X \\leq x, Y \\leq y) = P(X \\leq x) P(Y \\leq y) \\qquad$ for all $x$ and $y$ <br><br>\n","\n","\n",">Remember <br>\n",">Independence's slogan is multiply. <br>\n",">( we treated intuitive definition of independence before )\n","\n",">Preview <br>\n",">$P(X \\leq x, Y \\leq y)$ is called \" Joint CDF \" <br>\n",">probability simutaneously for $X$ and $Y$ <br>\n",">( we'll be considering much more later ! )\n","\n","<br><br>\n","\n","\" That's saying independence of the events ! \" <br><br>\n","This means that the event $X \\leq x$ is independent of the event $Y \\leq y$ ! <br>\n","\n",">Remeber <br>\n",">$X \\leq x \\quad \\leftarrow$ It's and event !\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"e4GbhuTXg-N2","colab_type":"text"},"source":["### Discrete case independence <br><br>\n","\n","\n","The definition of Independence is unwieldy $\\quad$ ( because of CDF ? ) <br>\n","It's easier work with the PMF $\\quad$ ( on discrete case ) <br>\n","\n",">It's hard to think about the jumpy funcntion <br>\n",">of the CMF of a discrete case ...\n","\n","<br>\n","\n","So in the discrete case, <br>\n","this equation (of independenc def.) is equivalent to <br>\n","$P(X=x, Y=y) = P(X=x)P(Y=y)$ <br><br>\n","\n","\n",">Intuitively <br>\n",">Independence means knowing the value of $X$ tells us nothing about the value of $Y$. <br>\n",">And that means the event $X=x$ should be independent the event $Y=y$.\n","\n",">This definition of independence won't work in the continuous case ! <br>\n",">because in the continuous case, this is $0=0*0$.\n","\n","\n","<br><br><br>\n","\n","\n","That's what it means for random variables to be independent.\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C7Ol9F1M5H-_","colab_type":"text"},"source":["## Average (Means, Expected valuse ) <br><br>\n","\n","\n","We want to know <br>\n","\" how we take the average of Random Variables \". \n","\n","<br><br><br>\n","\n","\n","\n","### General meaning of Average <br><br>\n","\n","There's more than one way to average bunch of numbers. <br>\n","Mean, Median, Mod ... <br>\n","\n",">If you just say average without any further clarification, <br>\n",">you can that's the mean. $\\quad$ ( cuz that's the ordinary averagy )\n","\n","<br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"z6hz8dF1kMaN","colab_type":"text"},"source":["### Why average is important on Random Variables ? <br><br>\n","\n","\n","  1. Average is telling you just one number summary of the center of the distribution in some sense ! <br>\n","  >There're some one-number summaries <br>\n","  >Variacne, Standrad Deviation, and Measures of variability ... \n","  \n","  <br>\n","\n","  2. Random Variables is things that we don't know don't know what value of it before we do experieance. <br>\n","  if let us do the experience, then we actually may get to obeserve the value ... <br>\n","  Beforehand, we may want to make some predictions. <br>\n","  $\\rightarrow \\quad$ We want to say on average what's going to happen !\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pYKs1L-Ctyag","colab_type":"text"},"source":["### Two ways of mean average <br><br>\n","\n","\n","  1. #### Unweighted average <br><br>\n","\n","  The simplest one of average <br>\n","  average of {1, 2, 3, ... , n} $\\quad = \\displaystyle \\frac{1 + 2 + 3 + ... + n}{n}$ <br><br>\n","\n","  Average of Arithmatic series <br>\n","$\\frac{1}{n} \\displaystyle \\sum_{j=1}^n j = \\frac{n+1}{2}$ <br>\n",">What Gaus did <br>\n",">This is unweighted averge. <br>\n",">Because every argument have the same weghit of $\\frac{1}{n}$ without grouping.\n","\n","<br><br><br>\n","\n","\n","\n","  2. #### Weighted average <br><br>\n","\n","  Average of non-ordered numbers <br>\n","  average of {1, 1, 1, 1, 1, 3, 3, } <br><br>\n","\n","  Notice. <br>\n","  There are two ways to do it <br>\n","  The key concept when we get to Random Variables to do average. \n","\n","<br><br>\n","\n","\n",">1. Ungrouped average <br>\n",">Add up (sum) all, and devide it by total number. <br><br>\n",">\n",">2. Weighted (sum) average <br>\n",">Group each same entries, and sum all each group wieghted by ratio <br><br>\n",">$\\frac{5}{8}*1 + \\frac{2}{8}*3 + \\frac{1}{8}*5$\n","\n","\n","\n","<br><br><br>\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lwtJVWhx4blO","colab_type":"text"},"source":["### Average of a discrete Random Variable $X$ <br><br>\n","\n","We're going to use the same idea of weighted average <br>\n","summing up values $x$ times weights $w$ <br>\n","the weight is the probabilities <br><br>\n","\n","We're going to give higher weight to the values that are more likely and lower weight to values that are unlikely. \n","\n","<br><br>\n","\n","\n","$\\begin{align}\n","\\mathbb{E} = &\\displaystyle \\sum_x x*P(X=x) \\qquad \\qquad \\text{, summed over $x$ with $P(X=x)>0$}\n","\\\\ &\\sum \\text{value} * \\text{PMF}\n","\\end{align}$ <br><br>\n","\n","\n","\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-2NCL4ed-6rx","colab_type":"text"},"source":["### Example of Average $\\quad : \\; X \\sim Bern(p) \\quad$ ( Bernoulli ) <br><br>\n","\n","\n","Brenoulli(P) means that it's only can equal 0 or 1. <br>\n","So that's very easy to deal with. \n","\n","<br><br>\n","\n","\n","The average of $X \\sim Bern(p)$ by definition <br><br>\n","\n","$\\begin{align}\n","\\mathbb{E} &= 1*P(X=1) + 0*P(X=0) \\\\\n","&= P\n","\\end{align}$ \n","\n","<br><br>\n","\n","\n","### Average of Indicator Random Vriables <br><br>\n","\n","#### Indicator Random Variable <br><br>\n","\n","There's something deeper going on ... <br>\n","Specific case of a Bernoulli Random Variable <br><br>\n","\n","Here is some event that we're interested in. <br>\n","$X = \\begin{cases} \n","1, \\quad A \\; \\text{occur} \\\\\n","0, \\quad \\text{otherwise}\n","\\end{cases}$ <br><br>\n","\n","Indicator R.V. is one of the Bernoulli R.V. <br>\n","So the average is ... <br><br>\n","\n","$\\mathbb{E}(X) = P(A)$ <br>\n",">$P(S)$ is the probability of the $A$.\n","\n","<br><br>\n","\n","\n","### Fundamental Bridge <br><br>\n","\n","This equation is pretty fundamental. <br>\n","So I call this thing \" the fundamental bridge \". <br><br>\n","\n","This bridges between Expected values and Probabilities ! <br><br>\n","\n","This says <br><br>\n","\n","In any problem you want in probability, <br>\n","if you have any event $A$ and that Probability $P(A)$, <br>\n","you can always reinterpret that as the Exoected vakue of an Indicator !  <br>\n","\n",">In a sense, we could have derived the probabilities from the Expected values.\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"M637UL0pOb7v","colab_type":"text"},"source":["### Example of Average $\\quad : \\; X \\sim Bin(n,p) \\quad$ ( Binomial ) <br><br>\n","\n","#### One way to do this $quad : \\;$ by the story <br><br>\n","\n","\n","$\\begin{align} \n","\\mathbb{E} \n","&= \\displaystyle \\sum_{k=0}^n k * \\binom{n}{k}p^kq^{n-k} \\\\\n","&= \\displaystyle \\sum_{k=0}^n n * \\binom{n-1}{k-1} p^k q^{n-k} &&\\text{... by the story of counting} \\\\\n","&= np \\displaystyle * \\sum_{k=0}^n \\binom{n-1}{k-1} p^{k-1} q^{n-k} \\\\\n","&= np \\displaystyle * \\sum_{j=0}^{n-1} \\binom{n-1}{j} p^{j} q^{n-j-1} &&\\text{... for using the binomial theorem} \\\\\n","&= np\n","\\end{align}$ <br><br>\n","\n","\n","the reason of 2nd line rewriting, <br>\n","Because $k$ depends on $k=0\\sim1$, but $n$ does not depend on $k=0\\sim1$. <br>\n","we change variable $k$ to constant $k$ that could come out.\n","\n","<br><br>\n","\n","\n","#### $\\binom{n}{k}$ is one of the story for counting ! <br>\n","\n","We talked about the fact that <br>\n","we have $n$ people and choose a committee of size $k$ with one person as president. <br>\n","\n",">We could either first choose the presidnet then choose the rest of the committee <br>\n",">or first choose the committe then choose the president from someone on the committee.\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"T_g--RoxUjxa","colab_type":"text"},"source":["### Linearity $\\quad : \\;$ the most important Property of Expectation <br><br>\n","\n","\n","  - $\\mathbb{E}(X+Y) = \\mathbb{E}(X) + \\mathbb{E}(Y)$ <br><br>\n","\n","  This is always true ! <br>\n","  ( Even if $X$ and $Y$ are dependent ! ) <br>\n","  >we'll do this proof next time ...\n","\n","<br>\n","\n","  - $\\mathbb{E}(cX) = c \\mathbb{E} (X) \\quad$ if $c$ is constant <br>\n","\n","\n","\n","\n","<br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EEmMtLJIWOQI","colab_type":"text"},"source":["#### Better way to do this $\\quad : \\;$ by the Linearity <br><br>\n","\n","Think about Linearity ! <br><br>\n","\n","\n","Remember <br>\n","the Binomial $Bin(n,p)$, we can think of it as the sum $n$ i.i.d. Bernoulli $p$s. <br>\n","Each of those bernoulli $Bern(p)$ has expected value $p$, and there's $n$ of them. <br><br>\n","\n","So the average of $X \\sim Bin(n,p)$ is <br>\n","$\\mathbb{E} = np \\qquad \\qquad$ ... by Linearity <br><br>\n","\n","Since <br>\n","$X_1 + X_2 + ... + X+n$ <br>\n","$X_i \\sim Bern(p)$ <br><br>\n","\n","for the Binomial, we can actually think of these $X_i \\sim Bern(p)$ as independent Bernoullies. <br><br>\n","\n","But even if these Bernoullis $X_i \\sim Bern(p)$ were dependent, <br>\n","it's still true ! $\\quad$ ( it's still gonna be $\\mathbb{E}(X ) = np$ ) <br>\n","\n","\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xXUB5Ynchev8","colab_type":"text"},"source":["### Example of Average $\\quad : \\; X \\sim ??? \\quad$ ( Hypergeometry ) <br><br>\n","\n","\n","Remember <br>\n","the Hypergeometric PMF involves Binomial coefficients ( and looks pretty complicate ... ) <br><br>\n","\n","Instead, let's just think in terms of Indicator Random Variables !\n","\n","<br><br>\n","\n","EX. <br>\n","When 5 card hand and $X = \\#Aces$, <br>\n","$\\mathbb{E} = ?$ <br>\n","\n","<br>\n","\n","Let $X_j$ be Indicator of the event \" $j$th card being an Ace \", $1 \\leq j \\leq 5$ <br>\n","( There's no matter that the card is odered. but just for concrete thinking ) <br>\n","So I have five of these Indicator Rnadom Vaiables.  <br><br>\n","\n","Therefore, <br>\n","we can think of $X$ as just being the sum of these Indicators <br>\n","( that's just the way how we count the card ) <br><br>\n","\n","$\\begin{align} \\mathbb{E}\n","&= \\mathbb{E}(X_1, + X_2 + ... + X_5) &&\\text{... by Indicator R.V.} \\\\\n","&= \\mathbb{E}(X_1) + \\mathbb{E}(X_2) + ... + \\mathbb{E}(X_5) &&\\text{... by Linearity} \\\\\n","&= 5 \\mathbb{E}(X_1) &&\\text{... by Symmetry} \\\\\n","&= 5 P(\\text{1st card is an Ace}) &&\\text{... by Fundamental bridge !} \\\\\n","&&&\\text{... $\\mathbb{E}(X_1)$ is the same as the probability that that card is an Ace} \\\\\n","&= \\frac{5}{13} &&\\text{even though $X_j$s are dependent !}\n","\\end{align}$ <br><br>\n","\n",">by Symmetry ... <br>\n",">there's no reason to think that the second card has a different distribution from the fifth card. <br>\n",">It's completely symmetrical ! \n","\n",">even though $X_j$s are dependent ... <br>\n",">for example, if the first four cards are Aces, the fifth one couldn't be Ace ! <br>\n",">But Linearity still says it's still true.\n","\n","<br><br>\n","\n","\n","Using this tools together is often very powerful strategy <br>\n","You can solve a lot of problems. with them. <br><br>\n","\n","$\\text{Indicator} \\rightarrow \\text{Linearity} \\rightarrow \\text{Symmetry} \\rightarrow \\text{Fundamental bridge}$ \n","\n","\n","<br><br>\n","\n","\n","In general, <br>\n","This gives Expected value of any Hypergeometric <br><br>\n","\n","Even though the Hypergeometric's trials are dependent, <br>\n","What this says is that for the expected value it still looks as if it were Binomial even though it's not ! <br><br>\n","\n","So also in Hypergeometric <br>\n","the expected value is $\\mathbb{E}(X) = np$ like Binomal ! \n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3jE31C8Vrub-","colab_type":"text"},"source":["### Geometric Distribution $\\quad Goem(p)$ <br><br>\n","\n","Not to be confused with the Hypergeometric ! <br>\n",">There's very little in common between the Geometric and Hypergeometric ...\n","\n","<br><br>\n","\n","\n","Story of Geometry <br>\n","In the independent $Bern(p)$ trials, count $\\#\\text{failure}$ before the $1$st success. <br>\n",">Independent Bernoulli trials is for example flipping a coin. <br>\n",">( or anything where you're repeating the same experience over and over again )\n","\n","<br><br>\n","\n","\n","Illustration of the picture $\\quad$ ( One specific trial of Geometric Random Variable ) <br>\n","F F F F F S <br>\n","Maybe we got five failures and then a success. <br>\n","the probability of that happening $P(X=5) = q^5 p$ <br><br>\n","\n","Here, <br>\n","\" this event is the only possible sequence of the $X=5$ ! \" \n","\n","<br><br>\n","\n","\n","PMF in general <br>\n","$\\begin{align} \n","&\\text{Let } \\; X \\sim Geom(p) &&\\text{the possible values are} \\;\\; 0, 1, 2, ... etc. \\\\\n","&&&q = 1 - p \\\\\n","&P(X=k) = q^k p && k \\in \\{ 0, 1, 2, ... \\}\n","\\end{align}$ \n","\n","<br><br><br>\n","\n","\n","\n","#### Difference of Geometric and Binomial <br>\n","\n",">In the Binomial distribution, <br>\n",">there's a fixed number of trials $n$ ( as an event $x$ ? )\n","\n",">In the Geometric distribution, <br>\n",">there's non-fixed number of trials ! ( unlike the Binomial ) <br>\n",">if at first you don't succeed you try it, try it,  and try It again until eventually you succeed. <br>\n",">and then you count how many failure you've had up until that point.\n","\n","<br><br><br>\n","\n","\n","\n","### Check a validation of PMF <br><br>\n","\n","\n","  1. $\\begin{align} \\displaystyle \\sum_{k=0}^\\infty p q^k &= \\frac{p}{1-q} \\qquad \\qquad \\big( \\sum_{k=0}^\\infty q^k = \\frac{1}{1-q} \\quad \\text{is just a geometric series !} \\big) \\\\\n","  &= 1\n","  \\end{align}$ <br>\n","  >That's why this is called the Geometric distribution. <br>\n","  >there's a geometric series. $\\quad$ ( like Binomial dist. had a binomial theorem in that )\n","\n","<br><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BsDkBP1Bc7aa","colab_type":"text"},"source":["### Expected value of Geometric dist. <br><br>\n","\n","\n","There's more than one way to do this. <br><br>\n","\n","$X \\sim Geom(p), \\quad$ compute the expected value of $X$ \n","\n","<br><br><br>\n","\n","\n","\n","  1. By the definition of expected value <br>\n","  ( the sum of values weighted probabilities ) <br><br>\n","\n","  $\\begin{align}\n","  &\\mathbb{E}(X) &&= \\displaystyle \\sum_{k=0}^\\infty k p q^k &&\\text{( the sum of values time PMF )} \\\\\n","  &&&= p \\sum_{k=0}^\\infty k q^k &&\\text{... What's that ?!}\n","  \\end{align}$ <br><br>\n","\n","  >When we face what we don't know, <br>\n","  >the strategy is start with things that we know, and try to reduce it back to what we're looking for ! <br><br>\n","  >\n","  >The only thing we know is that that's related to the geometric series $\\sum_{k=0}^\\infty q^k = 1/(1-q)$. <br>\n","  >( We know how to do this without the $k$ ! ) <br><br>\n","  >\n","  >Then, somehow I need to get $k$. <br>\n","  >by the derivative somehow we can get $k$ from $q^k$ ! <br>\n","  >$\\begin{align} \n","  &\\displaystyle \\sum_{k=0}^\\infty k q^{k-1} &&= \\frac{1}{(1-q)^2} \\\\\n","  &\\displaystyle \\sum_{k=0}^\\infty k q^k &&= \\frac{q}{(1-q)^2} &&\\text{... now it looks very similar to upper one} \\\\\n","  &&&= \\frac{q}{p} &&\\text{... by $p=1-q$}\n","  \\end{align}$ \n","  \n","  <br>\n","\n","  So ... <br>\n","  $\\begin{align} \n","  &\\mathbb{E}(X) &&= \\displaystyle p \\sum_{k=0}^\\infty k q^{k-1} \\\\\n","  &&&= \\frac{pq}{p^2} \\\\\n","  &&&= \\frac{q}{p}\n","  \\end{align}$\n","\n","<br><br><br>\n","\n","\n","\n","  2. Story Proof method <br><br>\n","\n","  Let's $\\; c = \\mathbb{E}(X) \\qquad$ , and we're trying to solve for $c$. <br>\n","  $\\rightarrow \\quad$ Recursive solution (재귀적 접근) <br>\n","  $\\qquad$ ( Gamlber's Ruin problem that we've seen before ) <br><br>\n","\n","  for example, <br>\n","  when flipping a coin with probability $p$ of heads over and over again <br>\n","  until the coin leands heads for the first time, <br>\n","  count the number of failures. <br><br><br>\n","\n","  There's two cases ! $\\qquad$ ( this is very similar to the First-step Analysis like the Gamblers Ruin ) <br><br>\n","  \n","    - First case, we success the first time (trial). <br>\n","    Either the first coing flip is heads, in that case $x=0$ because we had no failure. <br>\n","    $0*p$ <br><br>\n","    - The other case, we fail the first time (trial). <br>\n","    This happens with probability $q$, and then occure the same problem restart again $(1+c)$ <br>\n","    (1+c)*q <br>\n","    >The coin is the memoryless coin. The first trial doesn't affect later trials.\n","  \n","  <br>\n","  $\\begin{align}\n","  &c &&= 0*p + (1+c)*q \\\\\n","  &&&= q + c*q \\\\\n","  &&&= \\frac{q}{p} &&\\text{... by $p=1-q$}\n","  \\end{align}$ <br><br>\n","\n","  >I like more this way <br>\n","  >because without any calculus, we just write down what does it mean to to Geometric in the story !\n","\n","<br><br><br>\n","\n","\n"]}]}